
# kafka 3.4.0
### Ref. https://github.com/apache/kafka/tree/3.4.0

1. AbstractIndex:

```scala
/**
 * @param _file The index file
 * @param baseOffset the base offset of the segment that this index is corresponding to.
 * @param maxIndexSize The maximum index size in bytes.
 */
  // init class cosntructor
  abstract class AbstractIndex(@volatile private var _file: File, val baseOffset: Long, val maxIndexSize: Int = -1,
                             val writable: Boolean) extends Closeable

  // exist or null
  private volatile File file;
  // Length of the index file
  private var _length: Long = _

  // Offset Index override def entrySize = 8
  // Time Index override def entrySize = 12
  protected def entrySize: Int
 
  /*
   We can't set make N (_warmEntries) to be larger than 8192, as there is no simple way to guarantee all the "warm"
   section pages are really warm (touched in every lookup) on a typical 4KB-page host.
   1. When doing warm-section lookup, following 3 entries are always touched: indexEntry(end), indexEntry(end-N),
      and indexEntry((end*2 -N)/2). If page size >= 4096, all the warm-section pages (3 or fewer) are touched, when we
      touch those 3 entries. As of 2018, 4096 is the smallest page size for all the processors (x86-32, x86-64, MIPS,
      SPARC, Power, ARM etc.).
   2. This number is large enough to guarantee most of the in-sync lookups are in the warm-section. With default Kafka
      settings, 8KB index corresponds to about 4MB (offset index) or 2.7MB (time index) log messages.
  */
  // The warm entries should be no more than 3 pages.
  protected def _warmEntries: Int = 8192 / entrySize

  // Tread Lock
  protected val lock = new ReentrantLock

  // *** write data to channel, this is the most important part, // 重點
  // Kafka store bytes into a map per NIO thread
  protected var mmap: MappedByteBuffe

  // no more slots available in this index
  def isFull: Boolean = _entries >= _maxEntries
  def file: File = _file
  // The maximum number of entries this index can hold
  def maxEntries: Int = _maxEntries // = mmap.limit() / entrySize
  // The number of entries in this index
  def entries: Int = _entries // = mmap.position() / entrySize
  def length: Long = _length
  def updateParentDir(parentDir: File): Unit
  // Reset the size of the memory map and the underneath file
  // 1. trimToValidSize()
  // 2. loading segments from disk or truncating back to an old segment where a new log segment became active
  def resize(newSize: Int): Boolean

  def renameTo(f: File): Unit

  // force restore file
  def flush(): Unit 

  def deleteIfExists(): Boolean

  // The number of bytes actually used by this index
  def sizeInBytes: Int = entrySize * _entries

  //  close index 1. trimToValidSize 2. closeHandler
  def close(): Unit
  // prevent application threads(STW) for a long moment reading metadata from a physical disk.
  def closeHandler(): Unit

  def sanityCheck(): Unit

  // Remove all the entries from the index.
  protected def truncate(): Unit
  def truncateTo(offset: Long): Unit
  // 1. truncate 2. resize(maxIndexSize)
  def reset(): Unit

  // get offset relative to base offset of this index
  def relativeOffset(offset: Long): Int
  // check offset is valid
  def canAppendOffset(offset: Long): Boolean

  // delete mmap
  protected[log] def forceUnmap(): Unit

  // Windows and ZOS cannot resize, so we need to lock it
  protected def maybeLock[T](lock: Lock)(fun: => T): T 

  // get index entry
  protected def parseEntry(buffer: ByteBuffer, n: Int): IndexEntry
  // For offsetIndex, TimeIndex, lookup and truncateTo, find the slot in which the largest entry less than or equal to the given target key or value is stored.
  protected def largestLowerBoundSlotFor(idx: ByteBuffer, target: Long, searchEntity: IndexSearchType): Int
  // for offsetIndex fetchUpperBoundOffset, generally is  used to find the offset from the start index to the upper bound.
  protected def smallestUpperBoundSlotFor(idx: ByteBuffer, target: Long, searchEntity: IndexSearchType): Int
  // binary search is performed using _warmEntries (less than 3 pages) if possible, otherwise it is performed without _warmEntries. like LRU
  private def indexSlotRangeFor(idx: ByteBuffer, target: Long, searchEntity: IndexSearchType): (Int, Int)
  // search key or value
  private def compareIndexEntry(indexEntry: IndexEntry, target: Long, searchEntity: IndexSearchType): Int

  // Round a number to the greatest exact multiple of the given factor less than the given number.
  private def roundDownToExactMultiple(number: Int, factor: Int) = factor * (number / factor)
  
  // Offset is of type Long(8 Byte). Reserve 4 Byte (Delta) for each index, relativeOffset = offset - baseOffset
  private def toRelative(offset: Long): Option[Int]


```


2. OffsetIndex

In my opinion, storing offsets in a relative way is awesome since it can save a lot of space (4 bytes * n)!

```scala
  class OffsetIndex(_file: File, baseOffset: Long, maxIndexSize: Int = -1, writable: Boolean = true)
    extends AbstractIndex(_file, baseOffset, maxIndexSize, writable) 

  override def entrySize = 8
  /* the last offset in the index */
  private[this] var _lastOffset = lastEntry.offset


  class OffsetIndex(_file: File, baseOffset: Long, maxIndexSize: Int = -1, writable: Boolean = true)
    extends AbstractIndex(_file, baseOffset, maxIndexSize, writable)

    // find the position of the entry based on input offset
    private def lastEntry: OffsetPosition = {
      inLock(lock) {
        _entries match {
          case 0 => OffsetPosition(baseOffset, 0)
          case s => parseEntry(mmap, s - 1)
          }
        }
    }

  def lastOffset: Long = _lastOffset

  def lookup(targetOffset: Long): OffsetPosition

  // This is an offset which is guaranteed to be outside the fetched range
  def fetchUpperBoundOffset(fetchOffset: OffsetPosition, fetchSize: Int): Option[OffsetPosition]

  /*
  * The file format is a series of entries. The physical format is a 4 byte "relative" offset and a 4 byte file location for the
  * message with that offset. The offset stored is relative to the base offset of the index file. So, for example,
  * if the base offset was 50, then the offset 55 would be stored as 5. Using relative offsets in this way let's us use
  * only 4 bytes for the offset.
  */
  private def relativeOffset(buffer: ByteBuffer, n: Int): Int = buffer.getInt(n * entrySize)
  // locate exact physical position
  private def physical(buffer: ByteBuffer, n: Int): Int = buffer.getInt(n * entrySize + 4)

  //***
  override protected def parseEntry(buffer: ByteBuffer, n: Int): OffsetPosition = {
    OffsetPosition(baseOffset + relativeOffset(buffer, n), physical(buffer, n))
  }

// Get the nth offset mapping from the index, use parseEntry
  def entry(n: Int): OffsetPosition

  // 1. Check if the file can be written, _entries == 0 || offset > _lastOffset.
  // 2. Insert mmap and check _entries * entrySize == mmap.position()
  def append(offset: Long, position: Int): Unit

  override def truncate(): Unit = truncateToEntries(0)

 // find largestLowerBoundSlotFor by Binary Search
/* There are 3 cases for choosing the new size
  * 1) if there is no entry in the index <= the offset, delete everything, newEntries = 0
  * 2) if there is an entry for this exact offset, delete it and everything larger than it
  * 3) if there is no entry for this offset, delete everything larger than the next smallest
  */
  override def truncateTo(offset: Long): Unit

  // 1. check offset is valid, _entries != 0 && _lastOffset < baseOffset 
  // 2. length % entrySize != 0)
  override def sanityCheck(): Unit
```


3. TimeIndex
```scala
  override def entrySize = 12
  override def isFull: Boolean = entries >= maxEntries - 1
  private def timestamp(buffer: ByteBuffer, n: Int): Long = buffer.getLong(n * entrySize)
  private def relativeOffset(buffer: ByteBuffer, n: Int): Int = buffer.getInt(n * entrySize + 8)
  def lastEntry: TimestampOffset = _lastEntry
  // Read the last entry from the index file. This operation involves disk access.
  private def lastEntryFromIndexFile: TimestampOffset = {
    inLock(lock) {
      _entries match {
        case 0 => TimestampOffset(RecordBatch.NO_TIMESTAMP, baseOffset)
        case s => parseEntry(mmap, s - 1)
      }
    }
  }

  // Get the nth timestamp mapping from the time index
  def entry(n: Int): TimestampOffset

  override def parseEntry(buffer: ByteBuffer, n: Int): TimestampOffset = {
    TimestampOffset(timestamp(buffer, n), baseOffset + relativeOffset(buffer, n))
  }
  // 1. check not full
  // 2. _entries != 0 && timestamp < lastEntry.timestamp
  // 3. timestamp > lastEntry.timestamp
  // 4. update mmap, _lastEntry, assert _entries * entrySize == mmap.position()
  def maybeAppend(timestamp: Long, offset: Long, skipFullCheck: Boolean = false): Unit
  // 1. copy mmap
  // 2. binary search largestLowerBoundSlotFor
  def lookup(targetTimestamp: Long): TimestampOffset

  override def truncate(): Unit = truncateToEntries(0)
  /* There are 3 cases for choosing the new size
  * 1) if there is no entry in the index <= the offset, delete everything, newEntries = 0
  * 2) if there is an entry for this exact offset, delete it and everything larger than it
  * 3) if there is no entry for this offset, delete everything larger than the next smallest
  */
  override def truncateTo(offset: Long): Unit
  private def truncateToEntries(entries: Int): Unit
  override def resize(newSize: Int): Boolean

  // 1. _entries != 0 && lastTimestamp < timestamp(mmap, 0)
  // 2. _entries != 0 && lastOffset < baseOffset
  // 3. length % entrySize != 0
  override def sanityCheck():
```


4. LazyIndex

 * [From doc] This is an important optimization with regards to broker start-up and shutdown time, if it has a large number of segments.
 * Initialize the index using abstrct class for a wrapped index, and then call it with a lock while considering thread safety.
 * zh-tw: 即初始化時包裝索引並加鎖，使用後解鎖，達到不用主動取得 init 的 index.


```scala
  // lock
  private val lock = new ReentrantLock()
  def file: File

  // From IndexWrapper
  def updateParentDir(parentDir: File): Unit
  def renameTo(f: File): Unit
  def deleteIfExists(): Boolean
  def close()
  def closeHandler(): Unit
```

`implement`
```java
  public static class IndexFile
  public static class IndexValue<T>
```

